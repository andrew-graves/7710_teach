---
title: "Lab 2"
author: "Andrew Graves"
date: "September 18/20, 2019"
output:
  ioslides_presentation:
    smaller: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE, fig.height = 4)
```

## About me

3rd year Psychology PhD student

- Major concentration: Cognitive
- Minor concentration: Quantitative

Research interests

- Substantive: Long-term memory, face recognition, associative learning
- Methodological: Neuroimaging, signal analysis, reproducibility

Lab goals

- Reinforce statistical concepts from lecture **through** programming.

- Develop skills towards concise, legible, reproducible analysis workflows.

- Increase comfort with data manipulation, data visualization, and functional programming within base R **AND** the R ecosystem of software libraries.

- Including but not limited to core packages within the tidyverse (e.g. ggplot2, dplyr, etc.).

## Note on R programming styles

I typically utilize tidyverse libraries for my work in R.

- I will introduce the tidyverse framework, not because you need to use it, but because it will be good exposure for parsing code you find on the internet, as well as elucidate the code I present in class. 

Please do not feel like you need to use tidyverse libraries to perform your analyses! There are several ways to perform basic operations within R.

- I am happy to answer questions about tidy code during the in-class activities as well as in office-hours. 

One major difference is use of the pipe operator (%>%)

```{r pipe, eval = FALSE}
# Allows for complex data pipelines without writing intermediate objects
data_output <- data_input %>%
  first_function(arg1) %>%
  second_function(arg2, arg3) %>%
  third_function()

# Here is the base R equivalent w/o intermediate objects
data_output <- third_function(second_function(first_function(
  data_input, arg1), arg2, arg3))
```

# Quick Review

## Confidence Intervals

Definition: A range of values so defined that there is a specified probability that the value of a parameter lies within it.

- This is not the same as the range in which 95% of the data points fall.

Standard Deviation:
$$Standard Deviation (S) = \sqrt{\frac{\sum_{i=1}^n (X_i - \bar{X})^2}{n-1}}$$
Standard Error:
$$SD(\bar{X}) = \frac{SD}{\sqrt{n}}$$

All else equal, as *n* increases, the standard error decreases and the subsequent confidence interval narrows. 

## Distributions of parameters

If we simulate random data from a normal distribution with known parameters ($\mu$, $\sigma$), computing 95% confidence intervals is straightforward.

```{r r_norm}
data_1 <- rnorm(10000, mean = 3, sd = 6)

sq_deviance <- (data_1 - mean(data_1))^2
unbiased_n <- length(data_1) - 1

sd_data <- sqrt(sum(sq_deviance) / unbiased_n)
print(sd_data)

se_data <- sd_data / sqrt(length(data_1))
print(se_data)

lower_ci <- mean(data_1) + qnorm(.025) * se_data
upper_ci <- mean(data_1) + qnorm(.975) * se_data
```

# Some real-world data exploration

## Load packages and data
```{r pckgs_data}
library(tidyverse)
library(rtdists)
data(rr98)

# Check for redundant column
all.equal(rr98$response_num, as.numeric(rr98$response))

# Remove redundant column
rt_data_w_outliers <- rr98 %>%
  select(-response_num) %>%
  mutate(instruction = recode(instruction, 
  "accuracy" = "Accuracy",
  "speed" = "Speed")) %>%
  as_tibble()

rt_data <- rt_data_w_outliers %>%
  filter(!outlier)

# Modify ggplot themes
theme_set(theme_bw())
theme_update(text = element_text(family = "serif"), 
axis.title.y = element_text(margin = margin(t = 0, r = 20, b = 0, l = 0)))
```

## Print the data
```{r glimpse}
glimpse(rt_data)
```

## Explore the data

Description: Responses and response times from an experiment in which three participants were asked to decide whether the overall brightness of pixel arrays displayed on a computer monitor was "high" or "low". In addition, instruction manipulated speed and accuracy between blocks.

```{r explore}
# This function takes in a data frame (data) a dv (dv) and factor to facet
# on (facet), plotting a histogram with appropriate bin size. 

facet_hist <- function(data, dv, facet){
  
  # Enquo allows you to call tidyverse functions on variable names 
  # as function inputs. It puts the name "in quotes"
  dv <- enquo(dv)
  facet <- enquo(facet)
  
  # The !! operator allows you to reference enquo() objects 
  # in tidyverse functions
  data %>%
    ggplot() + 
    geom_histogram(aes(x = !!dv), bins = sqrt(nrow(data))) + 
    facet_wrap(c(facet)) + 
    labs(x = "RT", y = "Count")
}
```

Call ?rr98 if you want to learn more about the dataset.

## Does instruction impact RT?
```{r speed_acc}
facet_hist(rt_data_w_outliers, dv = rt, facet = instruction)
```

## Removing outliers
```{r no_outliers}
facet_hist(rt_data, dv = rt, facet = instruction)
```

## Do the participants differ?
```{r part_plot}
facet_hist(rt_data, dv = rt, facet = id)
```

## Bootstrap function
```{r boot, eval = TRUE}
# This function takes in a data vector (x), generates n samples from that
# vector on a specified number of iterations, and a function to
# bootstrap a parameter. The output is a data frame with the distribution, 
# mean estimates, and quantiles spanning 95% of the estimate. 
bootstrap <- function(x, n = length(x), iter, func){
  set.seed(42)
  boot <- rep(NA, iter)
  
  for (i in 1:iter){
  boot[i] <- sample(x, n, replace = TRUE) %>%
    func()
  }
  data <- data.frame(samp = boot, n = n,
                     iter = iter, mean = mean(boot),
                     lower = unname(quantile(boot, .025)),
                     upper = unname(quantile(boot, .975)))
}

# Creates every combination of both vectors
grid <- expand.grid(seq(50, 2500, 50), c(10, 100, 1000))
# Map (apply) the bootsrap function over all grid combinations and 
# compute the variance
boot_data <- map2_dfr(grid$Var1, grid$Var2, bootstrap, x = rt_data$rt, func = var)
```

## Validate bootstrap function

Let's make sure our bootstrap function approximates our simulation earlier when we used rnorm().

```{r random}
# Data from rnorm
c(lower_ci, mean(data_1), upper_ci)

check_mean <- bootstrap(data_1, iter = 10000, func = mean)

# Data from bootstrap
c(unique(check_mean$lower), mean(check_mean$samp), unique(check_mean$upper))
```
## Plot bootstrapped variance of RTs

```{r plot_boot, fig.width = 8, fig.height = 3}
(boot_plot_1 <- boot_data %>%
  ggplot(aes(x = n, y = mean, group = iter, color = factor(iter))) + 
  geom_line() +
  geom_point() + 
  scale_color_brewer(palette = "Set1") +
  labs(x = "Sample size", y = "Bootstrapped variance RT estimates",
       color = "Iteration #"))
```

## Now with error bars...

What trends do you notice?

```{r plot_boot_error, fig.width = 8, fig.height = 3}
boot_plot_1 + 
  geom_errorbar(aes(ymin = lower, ymax = upper, color = factor(iter)),
                position = position_dodge(width = 10))
```

## Bootstrapped confidence intervals

Let's bootstrap the binomially distributed accuracy variable and compute quantiles in which 95% of the parameter estimates fall between
```{r boot_acc}
# Subset data to one individual
jf_data <- rt_data %>%
  filter(id == "jf")

# Create two separate datasets based on instruction
speed <- jf_data %>%
  filter(instruction == "Speed")

accuracy <- jf_data %>%
  filter(instruction == "Accuracy")

# Bootstrap the accuracy for both instructions 
boot_data_acc <- bootstrap(x = accuracy$correct, iter = 10000,
  func = mean)
boot_data_speed <- bootstrap(x = speed$correct, iter = 10000,
  func = mean)
bind_boot <- bind_rows(boot_data_acc, boot_data_speed, .id = "Instruction") 
bind_boot <- bind_boot %>%
  mutate(Instruction = recode(Instruction, 
  `1` = "Accuracy",
  `2` = "Speed"))
```

## Code for next slide's plot
```{r plot_code}
acc_plot <- bind_boot %>%
  ggplot(aes(x = samp, fill = Instruction)) + 
  geom_histogram(aes(y = ..density..), bins = 100) + 
  stat_function(fun = dnorm, lwd = 1,
    args=list(mean = mean(boot_data_acc$samp), sd = sd(boot_data_acc$samp))) +
  geom_vline(aes(xintercept = quantile(boot_data_acc$samp, .025)), 
    lty = 2) + 
  geom_vline(aes(xintercept = quantile(boot_data_acc$samp, .975)), 
    lty = 2) +  
  stat_function(fun = dnorm, lwd = 1,
    args=list(mean = mean(boot_data_speed$samp), sd = sd(boot_data_speed$samp))) +
  geom_vline(aes(xintercept = quantile(boot_data_speed$samp, .025)), 
    lty = 2) + 
  geom_vline(aes(xintercept = quantile(boot_data_speed$samp, .975)), 
             lty = 2) +
  xlab("Bootstrapped mean accuracy estimates")
```

## Print the plot

There seems to be evidence for the speed-accuracy tradeoff on the accuracy dimension within the experiment. 
```{r print_acc_plot, fig.height = 3}
print(acc_plot)
```

# Now it's your turn!

Download the in-class activity and answer the questions as best you can. 

Collaborate with your peers to write code. 

I am available for programming questions.